interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - openrouter.ai
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://openrouter.ai/api/v1/models
  response:
    body:
      string: '{"data": [{"id": "anthropic/claude-sonnet-4", "canonical_slug": "anthropic/claude-4-sonnet-20250522",
        "hugging_face_id": "", "name": "Anthropic: Claude Sonnet 4", "created": 1747930371,
        "description": "Claude Sonnet 4 significantly enhances the capabilities of
        its predecessor, Sonnet 3.7, excelling in both coding and reasoning tasks
        with improved precision and controllability. Achieving state-of-the-art performance
        on SWE-bench (72.7%), Sonnet 4 balances capability and computational efficiency,
        making it suitable for a broad range of applications from routine coding tasks
        to complex software development projects. Key enhancements include improved
        autonomous codebase navigation, reduced error rates in agent-driven workflows,
        and increased reliability in following intricate instructions. Sonnet 4 is
        optimized for practical everyday use, providing advanced reasoning capabilities
        while maintaining efficiency and responsiveness in diverse internal and external
        scenarios.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-4)",
        "context_length": 200000, "architecture": {"modality": "text+image->text",
        "input_modalities": ["image", "text"], "output_modalities": ["text"], "tokenizer":
        "Claude", "instruct_type": null}, "pricing": {"prompt": "0.000003", "completion":
        "0.000015", "request": "0", "image": "0.0048", "audio": "0", "web_search":
        "0", "internal_reasoning": "0", "input_cache_read": "0.0000003", "input_cache_write":
        "0.00000375"}, "top_provider": {"context_length": 200000, "max_completion_tokens":
        64000, "is_moderated": false}, "per_request_limits": null, "supported_parameters":
        ["include_reasoning", "max_tokens", "reasoning", "stop", "temperature", "tool_choice",
        "tools", "top_k", "top_p"]}, {"id": "openai/gpt-4.1-mini", "canonical_slug":
        "openai/gpt-4.1-mini-2025-04-14", "hugging_face_id": "", "name": "OpenAI:
        GPT-4.1 Mini", "created": 1744651381, "description": "GPT-4.1 Mini is a mid-sized
        model delivering performance competitive with GPT-4o at substantially lower
        latency and cost. It retains a 1 million token context window and scores 45.1%
        on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini
        also shows strong coding ability (e.g., 31.6% on Aider\u2019s polyglot diff
        benchmark) and vision understanding, making it suitable for interactive applications
        with tight performance constraints.", "context_length": 1047576, "architecture":
        {"modality": "text+image->text", "input_modalities": ["image", "text", "file"],
        "output_modalities": ["text"], "tokenizer": "GPT", "instruct_type": null},
        "pricing": {"prompt": "0.0000004", "completion": "0.0000016", "request": "0",
        "image": "0", "audio": "0", "web_search": "0", "internal_reasoning": "0",
        "input_cache_read": "0.0000001"}, "top_provider": {"context_length": 1047576,
        "max_completion_tokens": 32768, "is_moderated": true}, "per_request_limits":
        null, "supported_parameters": ["frequency_penalty", "logit_bias", "logprobs",
        "max_tokens", "presence_penalty", "response_format", "seed", "stop", "structured_outputs",
        "temperature", "tool_choice", "tools", "top_logprobs", "top_p", "web_search_options"]},
        {"id": "anthropic/claude-3.5-sonnet", "canonical_slug": "anthropic/claude-3.5-sonnet",
        "hugging_face_id": null, "name": "Anthropic: Claude 3.5 Sonnet", "created":
        1729555200, "description": "New Claude 3.5 Sonnet delivers better-than-Opus
        capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet
        is particularly good at:\n\n- Coding: Scores ~49% on SWE-Bench Verified, higher
        than the last best score, and without any fancy prompt scaffolding\n- Data
        science: Augments human data science expertise; navigates unstructured data
        while using multiple tools for insights\n- Visual processing: excelling at
        interpreting charts, graphs, and images, accurately transcribing text to derive
        insights beyond just the text alone\n- Agentic tasks: exceptional tool use,
        making it great at agentic tasks (i.e. complex, multi-step problem solving
        tasks that require engaging with other systems)\n\n#multimodal", "context_length":
        200000, "architecture": {"modality": "text+image->text", "input_modalities":
        ["text", "image"], "output_modalities": ["text"], "tokenizer": "Claude", "instruct_type":
        null}, "pricing": {"prompt": "0.000003", "completion": "0.000015", "request":
        "0", "image": "0.0048", "audio": "0", "web_search": "0", "internal_reasoning":
        "0", "input_cache_read": "0.0000003", "input_cache_write": "0.00000375"},
        "top_provider": {"context_length": 200000, "max_completion_tokens": 8192,
        "is_moderated": true}, "per_request_limits": null, "supported_parameters":
        ["max_tokens", "stop", "temperature", "tool_choice", "tools", "top_k", "top_p"]},
        {"id": "openai/gpt-4o", "canonical_slug": "openai/gpt-4o", "hugging_face_id":
        null, "name": "OpenAI: GPT-4o", "created": 1715558400, "description": "GPT-4o
        (\"o\" for \"omni\") is OpenAI''s latest AI model, supporting both text and
        image inputs with text outputs. It maintains the intelligence level of [GPT-4
        Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more
        cost-effective. GPT-4o also offers improved performance in processing non-English
        languages and enhanced visual capabilities.\n\nFor benchmarking against other
        models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
        "context_length": 128000, "architecture": {"modality": "text+image->text",
        "input_modalities": ["text", "image", "file"], "output_modalities": ["text"],
        "tokenizer": "GPT", "instruct_type": null}, "pricing": {"prompt": "0.0000025",
        "completion": "0.00001", "request": "0", "image": "0.003613", "audio": "0",
        "web_search": "0", "internal_reasoning": "0", "input_cache_read": "0.00000125"},
        "top_provider": {"context_length": 128000, "max_completion_tokens": 16384,
        "is_moderated": true}, "per_request_limits": null, "supported_parameters":
        ["frequency_penalty", "logit_bias", "logprobs", "max_tokens", "presence_penalty",
        "response_format", "seed", "stop", "structured_outputs", "temperature", "tool_choice",
        "tools", "top_logprobs", "top_p", "web_search_options"]}, {"id": "openai/gpt-3.5-turbo",
        "canonical_slug": "openai/gpt-3.5-turbo", "hugging_face_id": null, "name":
        "OpenAI: GPT-3.5 Turbo", "created": 1685232000, "description": "GPT-3.5 Turbo
        is OpenAI''s fastest model. It can understand and generate natural language
        or code, and is optimized for chat and traditional completion tasks.\n\nTraining
        data up to Sep 2021.", "context_length": 16385, "architecture": {"modality":
        "text->text", "input_modalities": ["text"], "output_modalities": ["text"],
        "tokenizer": "GPT", "instruct_type": null}, "pricing": {"prompt": "0.0000005",
        "completion": "0.0000015", "request": "0", "image": "0", "audio": "0", "web_search":
        "0", "internal_reasoning": "0"}, "top_provider": {"context_length": 16385,
        "max_completion_tokens": 4096, "is_moderated": true}, "per_request_limits":
        null, "supported_parameters": ["frequency_penalty", "logit_bias", "logprobs",
        "max_tokens", "presence_penalty", "response_format", "seed", "stop", "structured_outputs",
        "temperature", "tool_choice", "tools", "top_logprobs", "top_p"]}]}'
    headers:
      Access-Control-Allow-Origin:
      - '*'
      CDN-Cache-Control:
      - max-age=300
      CF-RAY:
      - 96aa883ebaefaf67-LAX
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Wed, 06 Aug 2025 00:49:03 GMT
      Permissions-Policy:
      - payment=(self "https://checkout.stripe.com" "https://connect-js.stripe.com"
        "https://js.stripe.com" "https://*.js.stripe.com" "https://hooks.stripe.com")
      Referrer-Policy:
      - no-referrer, strict-origin-when-cross-origin
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      X-Content-Type-Options:
      - nosniff
      content-length:
      - '417177'
    status:
      code: 200
      message: OK
version: 1
